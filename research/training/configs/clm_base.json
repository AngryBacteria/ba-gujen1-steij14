{
  "general": {
    "debug": true,
    "wandb_logging": false,
    "disable_annoying_warnings": false,
    "run_name": "BaseConfig",
    "gpu": 0,
    "save_model": false,
    "output_dir": "mistral_instruction_base",
    "save_steps": 0,
    "logs_per_epoch": 16
  },
  "model": {
    "id_model": "LeoLM/leo-mistral-hessianai-7b",
    "lower_precision": false,
    "attention_implementation": "sdpa",
    "lora": false,
    "qlora": false,
    "galore": false
  },
  "data_processing": {
    "sequence_length": 512,
    "processing_threads": 1,
    "test_size": 0.05
  },
  "trainer": {
    "epochs": 1,
    "batch_size": 1,
    "evals_per_epoch": 2,
    "optimizer": "adamw_torch_fused",
    "learning_rate": 0.00005,
    "warmup_ratio": 0.05,
    "gradient_accumulation_steps": 4,
    "gradient_checkpointing": true,
    "mixed_precision": false
  }
}
